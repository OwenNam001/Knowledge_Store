1. 데이터 Access

df.iloc[3:5]                                        # integer locatin으로 찾음 3 location row (header제외), 5 location column
df.iloc[3:5, 2], df.iloc[2:4, 0:4]                  # slicing 
df.iloc[2:, :4]                                     # row: 2 ~ , column: ~ 4
df.iloc[2:, [0,2,4]]                                # row: 2 ~ , column: 0,2,4
df.iloc[2:, :"Family"]                              # row: 2 ~ , column: ~ "Family"
df.iloc[:, 2],                                      # Select all rows for selected columns 
df.loc[:, "Family"],                                # Select all rows for selected columns 
df.loc[:, ["Family", "Threatened status"]]          # Select all rows for selected columns 

df["Family"] == "leonina"                           # select "Family", decode("Family", "leonina", True, False) form TAB

df = df.set_index('Species')                        # Species라는 컬럼을 index 컬럼으로 지정함
df.loc["leonina", "Family"]                         # select "Family" from TAB where Species = "leonina"
df.loc[(df["Threatened status"] == "Vulnerable"), :]  # select * from TAB where "Threatened status" = "Vulnerable"
df.loc[(df["GDP Values"] > 10000), :]                 # select * from TAB where "GDP Values" > 10000

# select * from TAB where "Threatened status" = "Vulnerable" AND "Common Name" = "Southern Elephant Seal"   
df.loc[(df["Threatened status"] == "Vulnerable") & (df["Common Name"] == "Southern Elephant Seal"), :]

# select * from TAB where "Threatened status" = "Vulnerable" OR "Common Name" = "Southern Elephant Seal"   
df.loc[(df["Threatened status"] == "Vulnerable") & (df["Common Name"] == "Southern Elephant Seal"), :]

2. DataFrame Join
# info_df와 item_df 두개의 DataFrame을 customer_id, order_id 컬럼으로 
pd.merge(info_df, item_df, on=["customer_id", "order_id"], how="inner")     # inner join
pd.merge(info_df, item_df, on=["customer_id", "order_id"], how="left")      # info_df를 기준으로 left join
pd.merge(info_df, item_df, on=["customer_id", "order_id"], how="right")     # item_df를 기준으로 right join
pd.merge(info_df, item_df, on=["customer_id", "order_id"], how="outer")     # 양쪽 full outer join

2. DataFrame Delete rows
item_df.dropna(how="any", subset=["columnA", "columnB"])   # how="any", columnA나 columnB중 하나라도 "NaN" (NULL)이 있으면 해당 row delete
item_df.dropna(how="all", subset=["columnA", "columnB"])   # how="all", columnA와 columnB가 모두 "NaN" (NULL)이 있으면 해당 row delete
item_df.dropna()                                           # 모든 컬럼을 뒤져 NULL이 하나라도 있으면 해당 row를 delete

2-0. null값을 특정 단어로 채움
road_stops_reduced.fillna({"SURFACE_TYPE": "Unknown"})

2-1. DataFrame Column remove
del employment_data_df['OCCUP_INDEX']

3. Add Compute column to existing DataFrame
item_df["New Column"] = (item_df["columnA"] / item_df["columnB"]) * 100

4. Sorting DataFrame, Sorting을 하고 나서 index를 reset을 해준다. default ascending order
<< 컬럼의 highest, lowest 순으로 데이터를 보여주고자 할때 쓴다. >>
item_sorted_df = item_df.sort_values(["ColumnC", "ColumnD"], ascending=False)

  # Reset Index
  item_sorted_df = item_sorted_df.reset_index(drop=True)

5. Data를 categorize하기
bins = [0, 60, 70, 80, 90, 100]          # Category boundary 값 지정
group_names = ["F", "D", "C", "B", "A"]  # 표시 lavel 지정

df["Score Summary"] = pd.cut(df["Test Score"], bins, labels=group_names, right=False)  #right=False : include left edge, exclude right edge

6. DataFrame Column format변경
file_df["INCOME"] = file_df["INCOME"].map("${:,.2f}".format)
file_df["COSTS"] = file_df["COSTS"].map("${:,.2f}".format)
file_df["PERCENT30"] = (file_df["PERCENT30"]*100).map("{:.1f}%".format)
file_df["PERCENT3050"] = (file_df["PERCENT3050"]*100).map("{:.1f}%".format)
file_df["PERCENT50"] = (file_df["PERCENT50"]*100).map("{:.1f}%".format)
file_df["PERCENT_NODATA"] = (file_df["PERCENT_NODATA"]*100).map("{:.1f}%".format)
file_df["PERCENT_NOBURDEN"] = (file_df["PERCENT_NOBURDEN"]*100).map("{:.1f}%".format)
file_df["TOTAL"] = file_df["TOTAL"].map("{:,}".format)

# Change "Postcode" column into integer
bug_infestations["Postcode"] = bug_infestations["Postcode"].astype("int64")

# First convert to float and to two decimal places, include a dollar sign, and use comma notation
hosted_in_aus_df["average_donation"] = hosted_in_aus_df["average_donation"].astype(float).map("${:,.2f}".format)

%가 들어있는 데이터에서 mean()을 하면 에러가 발생하므로 %를 지우고 float로 바꿔서 mean을 구하는 방법
# Converting the "Percentage" column to floats
veterans_df["Percentage"] = veterans_df["Percentage"].str.replace("%", "").astype('float')
veterans_df["Percentage"].mean()

7. DataFrame 컬럼명 rename
base_df.columns = ['close', 'normalised']                                            # 컬럼 rename 방법1
base_ren_df = base_df.rename(columns={"Date of publication":"Publication Year"} )    # 컬럼 rename 방법2

8. Date컬럼의 데이터를 datetime64 type으로 바꿔서 year를 추출하는 방법
# Extract the year from the date
bugs_df["Filing Date"] = bugs_df["Filing Date"].astype("datetime64")
bugs_df["Year"] = bugs_df["Filing Date"].dt.year

10. Group by 
df["LOCAL_GOVERNMENT_NAME"].value_counts()     # select "LOCAL_GOVERNMENT_NAME", count(*) from TAB group by "LOCAL_GOVERNMENT_NAME"

grouped_df = df.groupby(["LOCAL_GOVERNMENT_NAME", "SURFACE"])                   # "LOCAL_GOVERNMENT_NAME", "SURFACE" group by 컬럼을 주고
grouped_df.count()                                                              # 나머지 컬럼을 전부 count 한다.
grouped_df[["NUMBER_OF_BINS", "NUMBER_OF_TOILETS", "NUMBER_OF_TABLES"]].sum()   # 세개의 컬럼을 sum 한다. 

lg_toilets = grouped_df["NUMBER_OF_TOILETS"].sum()                              # 각각의 group by 결과를 각각의 Series로 만
lg_tables = grouped_df["NUMBER_OF_TABLES"].sum()
